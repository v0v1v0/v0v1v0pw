<div class="container">

<table style="width: 100%;"><tr>
<td>watson</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit Mixtures of Watson Distributions</h2>

<h3>Description</h3>

<p><code>watson</code> fits a finite mixture of multivariate Watson distributions.
</p>


<h3>Usage</h3>

<pre><code class="language-R">watson(x, k, control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric data matrix, with rows corresponding to observations. Can be a dense matrix,
or any of the supported sparse matrices from  <code>Matrix</code> package by <code>Rcpp</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>an integer giving the number of mixture components.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>a list of control parameters. See Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>a list of control parameters (overriding those specified in control).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>watson returns an object of class "watfit" representing the fitted mixture of Watson
distributions model. Available methods for such objects include <code>coef</code>, <code>logLik</code>, <code>print</code> and <code>predict</code>.
<code>predict</code> has an extra type argument with possible values <code>"class_ids"</code> (default) and <code>"memberships"</code>
for indicating hard or soft prediction, respectively.
</p>
<p>The mixture of Watson distributions is fitted using EM variants as specified by control
option E (specifying the E-step employed), with possible values "softmax" (default), "hardmax" or
"stochmax". For "stochmax", class assignments are drawn from the posteriors for each observation in the E-step as
outlined as SEM in Celeux and Govaert (1992). The stopping criterion for this algorithm is by default
changed to not check for convergence (logical control option converge), but to return the parameters with
the maximum likelihood encountered.
</p>
<p>In the M-step, the parameters of the respective component distributions
are estimated via maximum likelihood, which is accomplished by solving the equation
</p>
<p style="text-align: center;"><code class="reqn">g(\alpha,\beta, \kappa)=r,</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">0&lt;\alpha&lt;\beta,  \  0\leq r\leq 1</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">g(\alpha, \beta, \kappa) =  (\alpha/\beta)M(\alpha+1, \beta+1,  \kappa)/M(\alpha, \beta,  \kappa),</code>
</p>
<p> with M being the Kummer's function.
Via control argument M, one can specify how to (approximately) solve these equations.
The possible methods are:
</p>
<p>"Sra_2007"
uses the approximation of Sra (2007).
</p>
<p>"BBG"
uses the approximation of Bijral et al. (2007), without the correction term.
</p>
<p>"BBG_c"
uses the approximation of Bijral et al. (2007), with the correction term.
</p>
<p>"Sra_Karp_2013"
uses the bounds derived in Sra and Karp (2013), with the decision rule .
</p>
<p>"bisection"
uses a bisection to solve the problem using evaluation proposed in Writeup1 (2018).
</p>
<p>"newton"
uses a bracketet type of Neton algorithm to solve the problem using evaluation proposed in Writeup1 (2018). (Default.)
</p>
<p>"lognewton"
uses a bracketet type of Neton algorithm to solve the problem <code class="reqn">log(g((\alpha, \beta, \kappa)) = log(r)</code>
using evaluation proposed in Writeup1 (2018).
</p>
<p>Additional control parameters are as follows.
</p>
<p>maxiter
an integer giving the maximal number of EM iterations to be performed, default: 100.
</p>
<p>reltol
the minimum relative improvement of the objective function per iteration. If improvement is less, the EM
algorithm will stop under the assumption that no further significant improvement can be made, defaults
to sqrt(.Machine$double.eps).
</p>
<p>ids
either a vector of class memberships or TRUE which implies that the class memberships are obtained from
the attribute named "id" of the input data; these class memberships are used for initializing the EM
algorithm and the algorithm is stopped after the first iteration.
</p>
<p>init_iter
a numeric vector setting the number of diametrical clustering iterations to do, before the EM starts, default: 0.
</p>
<p>start
a specification of the starting values to be employed. Can be a list of matrices giving the memberships
of objects to components. This information is combined with the <code>init_iter</code> parameter and together form
the initialization procedure. If nothing is given, the starting values are drwan randomly.
</p>
<p>If several starting values are specified, the EM algorithm is performed individually to each starting
value, and the best solution found is returned.
</p>
<p>nruns
an integer giving the number of EM runs to be performed. Default: 1. Only used if start is not given.
</p>
<p>minweight
a numeric indicating the minimum prior probability. Components falling below this threshold are removed
during the iteration. If is greater than 1, the value is taken as the minimal number of observations in a component, default: 0 if
E = "softmax" and 2 if other type of E-method is used .
</p>
<p>converge
a logical, if TRUE the EM algorithm is stopped if the reltol criterion is met and the current parameter
estimate is returned. If FALSE the EM algorithm is run for maxiter iterations and the parametrizations
with the maximum likelihood encountered during the EM algorithm is returned. Default: TRUE, changed to
FALSE if E="stochmax".
</p>
<p>N
an integer indicating number of iteration used when the Kummer function is approximate, default: 30.
</p>
<p>verbose
a logical indicating whether to provide some output on algorithmic progress, default: FALSE.
</p>


<h3>Value</h3>

<p>An object of class "watfit" representing the fitted mixture, which is a list containing the fitted
weights, concentrations parameters (kappa), concentrations directions (mu) and further metadata.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Generate a sample with two orthogonal circles (negative kappas)
a &lt;- rmwat(n = 200, weights = c(0.5,0.5), kappa = c(-200,-200),
                        mu = matrix(c(1,1,1,-1,1,1),nrow = 3))
## Fit basic model
q &lt;- watson(a, 2)
## Fit the models, giving the true categories
q &lt;- watson(a, 2, ids=TRUE)
## Fit a model with hard-assignment, and 50 runs
q &lt;- watson(a, 2, E = "hard", nruns = 50)
## Print details
q
## Extract coefficients
coef(q)
## Calculate likelihood for new data
a2 &lt;- rmwat(n = 20, weights = c(0.5,0.5), kappa = c(-200,-200),
                        mu = matrix(c(1,1,1,-1,1,1),nrow = 3))
logLik(q, a2)
## Compare the fitted classes to the true ones:
table(True = attr(a, "id"), Fitted = predict(q))

</code></pre>


</div>