<div class="container">

<table style="width: 100%;"><tr>
<td>wordpiece_tokenize</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tokenize Sequence with Word Pieces</h2>

<h3>Description</h3>

<p>Given a sequence of text and a wordpiece vocabulary, tokenizes the text.
</p>


<h3>Usage</h3>

<pre><code class="language-R">wordpiece_tokenize(
  text,
  vocab = wordpiece_vocab(),
  unk_token = "[UNK]",
  max_chars = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>text</code></td>
<td>
<p>Character; text to tokenize.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vocab</code></td>
<td>
<p>Character vector of vocabulary tokens. The tokens are assumed to
be in order of index, with the first index taken as zero to be compatible
with Python implementations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unk_token</code></td>
<td>
<p>Token to represent unknown words.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_chars</code></td>
<td>
<p>Maximum length of word recognized.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list of named integer vectors, giving the tokenization of the input
sequences. The integer values are the token ids, and the names are the
tokens.
</p>


<h3>Examples</h3>

<pre><code class="language-R">tokens &lt;- wordpiece_tokenize(
  text = c(
    "I love tacos!",
    "I also kinda like apples."
  )
)
</code></pre>


</div>