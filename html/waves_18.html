<div class="container">

<table style="width: 100%;"><tr>
<td>test_spectra</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Test the performance of spectral models</h2>

<h3>Description</h3>

<p>Wrapper that trains models based spectral data to predict
reference values and reports model performance statistics
</p>


<h3>Usage</h3>

<pre><code class="language-R">test_spectra(
  train.data,
  num.iterations,
  test.data = NULL,
  pretreatment = 1,
  k.folds = 5,
  proportion.train = 0.7,
  tune.length = 50,
  model.method = "pls",
  best.model.metric = "RMSE",
  stratified.sampling = TRUE,
  cv.scheme = NULL,
  trial1 = NULL,
  trial2 = NULL,
  trial3 = NULL,
  split.test = FALSE,
  seed = 1,
  verbose = TRUE,
  wavelengths = deprecated(),
  preprocessing = deprecated(),
  output.summary = deprecated(),
  rf.variable.importance = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>train.data</code></td>
<td>
<p><code>data.frame</code> object of spectral data for input into a
spectral prediction model. First column contains unique identifiers, second
contains reference values, followed by spectral columns. Include no other
columns to right of spectra! Column names of spectra must start with "X"
and reference column must be named "reference".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.iterations</code></td>
<td>
<p>Number of training iterations to perform</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test.data</code></td>
<td>
<p><code>data.frame</code> with same specifications as <code>df</code>. Use
if specific test set is desired for hyperparameter tuning. If <code>NULL</code>,
function will automatically train with a stratified sample of 70%. Default
is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pretreatment</code></td>
<td>
<p>Number or list of numbers 1:13 corresponding to
desired pretreatment method(s):
</p>

<ol>
<li>
<p> Raw data (default)
</p>
</li>
<li>
<p> Standard normal variate (SNV)
</p>
</li>
<li>
<p> SNV and first derivative
</p>
</li>
<li>
<p> SNV and second derivative
</p>
</li>
<li>
<p> First derivative
</p>
</li>
<li>
<p> Second derivative
</p>
</li>
<li>
<p> Savitzky–Golay filter (SG)
</p>
</li>
<li>
<p> SNV and SG
</p>
</li>
<li>
<p> Gap-segment derivative (window size = 11)
</p>
</li>
<li>
<p> SG and first derivative (window size = 5)
</p>
</li>
<li>
<p> SG and first derivative (window size = 11)
</p>
</li>
<li>
<p> SG and second derivative (window size = 5)
</p>
</li>
<li>
<p> SG and second derivative (window size = 11)
</p>
</li>
</ol>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k.folds</code></td>
<td>
<p>Number indicating the number of folds for k-fold
cross-validation during model training. Default is 5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proportion.train</code></td>
<td>
<p>Fraction of samples to include in the training set.
Default is 0.7.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.length</code></td>
<td>
<p>Number delineating search space for tuning of the PLSR
hyperparameter <code>ncomp</code>. Must be set to 5 when using the random forest
algorithm (<code>model.method == rf</code>). Default is 50.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model.method</code></td>
<td>
<p>Model type to use for training. Valid options include:
</p>
 <ul>
<li>
<p> "pls": Partial least squares regression (Default) </p>
</li>
<li>
<p>"rf": Random forest </p>
</li>
<li>
<p> "svmLinear": Support vector machine with linear
kernel </p>
</li>
<li>
<p> "svmRadial": Support vector machine with radial kernel </p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best.model.metric</code></td>
<td>
<p>Metric used to decide which model is best. Must be
either "RMSE" or "Rsquared"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stratified.sampling</code></td>
<td>
<p>If <code>TRUE</code>, training and test sets will be
selected using stratified random sampling. This term is only used if
<code>test.data == NULL</code>. Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.scheme</code></td>
<td>
<p>A cross validation (CV) scheme from Jarquín et al., 2017.
Options for <code>cv.scheme</code> include:
</p>

<ul>
<li>
<p> "CV1": untested lines in tested environments
</p>
</li>
<li>
<p> "CV2": tested lines in tested environments
</p>
</li>
<li>
<p> "CV0": tested lines in untested environments
</p>
</li>
<li>
<p> "CV00": untested lines in untested environments
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trial1</code></td>
<td>
<p><code>data.frame</code> object that is for use only when
<code>cv.scheme</code> is provided. Contains the trial to be tested in subsequent
model training functions. The first column contains unique identifiers,
second contains genotypes, third contains reference values, followed by
spectral columns. Include no other columns to right of spectra! Column
names of spectra must start with "X", reference column must be named
"reference", and genotype column must be named "genotype".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trial2</code></td>
<td>
<p><code>data.frame</code> object that is for use only when
<code>cv.scheme</code> is provided. This data.frame contains a trial that has
overlapping genotypes with <code>trial1</code> but that were grown in a different
site/year (different environment). Formatting must be consistent with
<code>trial1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trial3</code></td>
<td>
<p><code>data.frame</code> object that is for use only when
<code>cv.scheme</code> is provided. This data.frame contains a trial that may or
may not contain genotypes that overlap with <code>trial1</code>. Formatting must
be consistent with <code>trial1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>split.test</code></td>
<td>
<p>boolean that allows for a fixed training set and a split
test set. Example// train model on data from two breeding programs and a
stratified subset (70%) of a third and test on the remaining samples
(30%)  of the third. If <code>FALSE</code>, the entire provided test set
<code>test.data</code> will remain as a testing set or if none is provided, 30%
of the provided <code>train.data</code> will be used for testing. Default is
<code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Integer to be used internally as input for <code>set.seed()</code>.
Only used if <code>stratified.sampling = TRUE</code>. In all other cases, seed
is set to the current iteration number. Default is 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>TRUE</code>, the number of rows removed through filtering
will be printed to the console. Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wavelengths</code></td>
<td>
<p>DEPRECATED <code>wavelengths</code> is no
longer supported; this information is now inferred from <code>df</code>
column names</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>preprocessing</code></td>
<td>
<p>DEPRECATED please use
<code>pretreatment</code> to specify the specific pretreatment(s) to test.
For behavior identical to that of <code>preprocessing = TRUE</code>, set
<code>pretreatment = 1:13</code>'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output.summary</code></td>
<td>
<p>DEPRECATED <code>output.summary = FALSE</code>
is no longer supported; a summary of output is always returned alongside
the full performance statistics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rf.variable.importance</code></td>
<td>
<p>DEPRECATED
<code>rf.variable.importance = FALSE</code> is no longer supported; variable
importance results are always returned if the <code>model.method</code> is
set to 'pls' or 'rf'.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Calls <code>pretreat_spectra</code>, <code>format_cv</code>,
and <code>train_spectra</code> functions.
</p>


<h3>Value</h3>

<p><code>list</code> of 5 objects:
</p>

<ol>
<li>
<p> 'model.list' is a <code>list</code> of trained model objects, one for each
pretreatment method specified by the <code>pretreatment</code> argument.
Each model is trained with all rows of <code>df</code>.
</p>
</li>
<li>
<p> 'summary.model.performance' is a <code>data.frame</code> containing summary
statistics across all model training iterations and pretreatments.
See below for a description of the summary statistics provided.
</p>
</li>
<li>
<p> 'model.performance' is a <code>data.frame</code> containing performance
statistics for each iteration of model training separately (see below).
</p>
</li>
<li>
<p> 'predictions' is a <code>data.frame</code> containing both reference and
predicted values for each test set entry in each iteration of
model training.
</p>
</li>
<li>
<p> 'importance' is a <code>data.frame</code> containing variable importance
results for each wavelength at each iteration of model training.
If <code>model.method</code> is not "pls" or "rf", this list item is <code>NULL</code>.
</p>
</li>
</ol>
<p>'summary.model.performance' and 'model.performance' <code>data.frames</code>
summary statistics include:
</p>

<ul>
<li>
<p> Tuned parameters depending on the model algorithm:
</p>

<ul>
<li> <p><strong>Best.n.comp</strong>, the best number of components
</p>
</li>
<li> <p><strong>Best.ntree</strong>, the best number of trees in an RF model
</p>
</li>
<li> <p><strong>Best.mtry</strong>, the best number of variables to include at
every decision point in an RF model
</p>
</li>
</ul>
</li>
<li> <p><strong>RMSECV</strong>, the root mean squared error of cross-validation
</p>
</li>
<li> <p><strong>R2cv</strong>, the coefficient of multiple determination of
cross-validation for PLSR models
</p>
</li>
<li> <p><strong>RMSEP</strong>, the root mean squared error of prediction
</p>
</li>
<li> <p><strong>R2p</strong>, the squared Pearson’s correlation between predicted and
observed test set values
</p>
</li>
<li> <p><strong>RPD</strong>, the ratio of standard deviation of observed test set
values to RMSEP
</p>
</li>
<li> <p><strong>RPIQ</strong>, the ratio of performance to interquartile difference
</p>
</li>
<li> <p><strong>CCC</strong>, the concordance correlation coefficient
</p>
</li>
<li> <p><strong>Bias</strong>, the average difference between the predicted and
observed values
</p>
</li>
<li> <p><strong>SEP</strong>, the standard error of prediction
</p>
</li>
<li> <p><strong>R2sp</strong>, the squared Spearman’s rank correlation between
predicted and observed test set values
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Jenna Hershberger <a href="mailto:jmh579@cornell.edu">jmh579@cornell.edu</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(magrittr)
ikeogu.2017 %&gt;%
  dplyr::rename(reference = DMC.oven,
                unique.id = sample.id) %&gt;%
  dplyr::select(unique.id, reference, dplyr::starts_with("X")) %&gt;%
  na.omit() %&gt;%
  test_spectra(
    train.data = .,
    tune.length = 3,
    num.iterations = 3,
    pretreatment = 1
  )

</code></pre>


</div>