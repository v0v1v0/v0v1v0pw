<div class="container">

<table style="width: 100%;"><tr>
<td>twkm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Two-level variable weighting clustering
</h2>

<h3>Description</h3>

<p>Two-level variable weighting clustering.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  twkm(x, centers, groups, lambda, eta, maxiter=100, delta=0.000001,
       maxrestart=10,seed=-1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>numeric matrix of observations and features.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centers</code></td>
<td>
<p>target number of clusters or the initial centers for
clustering.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>a string give the group information, formatted as
<code>"0,1,2,4;3,5;6,7,8"</code> or <code>"0-2,4;3,5;6-8"</code>, where
<code>";"</code> defines a group; or a vector of length of features, each
element of the vector indicates the group of the feature. For
example, <code>c(1,1,1,2,1,2,3,3,3)</code> is the same as
<code>"0-2,4;3,5;6-8"</code>, or even<br><code>c("a","a","a","b","a","b","c","c","c")</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>parameter of feature weight distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eta</code></td>
<td>
<p>parameter of group weight distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>maximum change allowed between iterations for convergence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxrestart</code></td>
<td>
<p>maximum number of restarts. Default is 10 so that we
stand a good chance of getting a full set of clusters. Normally, any
empty clusters that result are removed from the result, and so we may
obtain fewer than k clusters if we don't allow restarts(i.e.,
maxrestart=0). If &lt; 0, then there is no limit on the number of
restarts and we are much likely to get a full set of k clusters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>random seed. If it was set below 0, then a randomly
generated number will be assigned.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The two-level variable weighting clustering algorithm is a
extension to ewkm, which itself is a soft subspace clustering
method.
</p>
<p>The algorithm weights subspaces in both feature groups and individual
features.
</p>
<p>Always check the number of iterations, the number of restarts, and the
total number of iterations as they give a good indication of whether
the algorithm converged.
</p>
<p>As with any distance based algorithm, be sure to rescale your numeric
data so that large values do not bias the clustering. A quick
rescaling method to use is <code>scale</code>.
</p>


<h3>Value</h3>

<p>Return an object of class "kmeans" and "twkm", compatible with other
function that work with kmeans objects, such as the 'print'
method. The object is a list with the following components in addition
to the components of the kmeans object:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>A vector of integer (from 1:k) indicating the cluster
to which each point is allocated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centers</code></td>
<td>
<p>A matrix of cluster centers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>featureWeight</code></td>
<td>
<p>A vector of weights recording the relative
importance of each feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groupWeight</code></td>
<td>
<p>A vector of group weights recording the relative
importance of each feature group.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iterations</code></td>
<td>
<p>This report on the number of iterations before
termination. Check this to see whether the maxiters was reached. If so
then teh algorithm may not be converging, and thus the resulting
clustering may not be particularly good.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>restarts</code></td>
<td>
<p>The number of times the clustering restarted because
of a disappearing cluster resulting from one or more k-means having no
observations associated with it. An number here greater than zero
indicates that the algorithm is not converging on a clustering for the
given k. It is recommended that k be reduced.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>totalIterations</code></td>
<td>
<p>The total number of iterations over all
restarts.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>totolCost</code></td>
<td>
<p>The total cost calculated in the cost function.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Xiaojun Chen <a href="mailto:xjchen.hitsz@gmail.com">xjchen.hitsz@gmail.com</a>
</p>


<h3>References</h3>

<p>Xiaojun Chen, Xiaofei Xu, Joshua Zhexue Huang and Yunming Ye (2013).
TW-k-Means: Automated Two-level Variable Weighting Clustering
Algorithm for Multiview Data. IEEE Transactions on Knowledge and Data
Engineering, 25(4), 932â€“944.
</p>


<h3>See Also</h3>

<p><code>kmeans</code>
<code>ewkm</code>
<code>fgkm</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# The data twkm.sample has 2000 objects and 410 variables.
# Scale the data before clustering
x &lt;- scale(twkm.sample[,1:409])

# Group information is formated as below.
# Each group is separated by ';'.
strGroup &lt;- "0-75;76-291;292-355;356-402;403-408"
groups &lt;- c(rep(0, abs(0-75-1)), rep(1, abs(76-291-1)), rep(2, abs(292-355-1)),
            rep(3, abs(356-402-1)), rep(4, abs(403-408-1)))


# Use the twkm algorithm.
mytwkm &lt;- twkm(x, 10, strGroup, 3, 1, seed=19)
mytwkm2 &lt;- twkm(x, 10, groups, 3, 1, seed=19)
all.equal(mytwkm, mytwkm2)

# You can print the clustering result now.
mytwkm$cluster
mytwkm$featureWeight
mytwkm$groupWeight
mytwkm$iterations
mytwkm$restarts
mytwkm$totiters
mytwkm$totss

# Use a cluster validation method from package 'fpc'.

# real.cluster is the real class label of the data 'twkm.sample'.
real.cluster &lt;- twkm.sample[,410]

# cluster.stats() computes several distance based statistics.
kmstats &lt;- cluster.stats(d=dist(x), as.integer(mytwkm$cluster), real.cluster)

# corrected Rand index
kmstats$corrected.rand

# variation of information (VI) index
kmstats$vi


</code></pre>


</div>