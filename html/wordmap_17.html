<div class="container">

<table style="width: 100%;"><tr>
<td>textmodel_wordmap</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>A model for multinomial feature extraction and document classification</h2>

<h3>Description</h3>

<p>Wordmap is a model for multinomial feature extraction and document
classification. Its naive Bayesian algorithm allows users to train the model
on a large corpus with noisy labels given by document meta-data or keyword
matching.
</p>


<h3>Usage</h3>

<pre><code class="language-R">textmodel_wordmap(
  x,
  y,
  label = c("all", "max"),
  smooth = 1,
  boolean = FALSE,
  drop_label = TRUE,
  entropy = c("none", "global", "local", "average"),
  residual = FALSE,
  verbose = quanteda_options("verbose"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a dfm or fcm created by <code>quanteda::dfm()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a dfm or a sparse matrix that record class membership of the
documents. It can be created applying <code>quanteda::dfm_lookup()</code> to <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>label</code></td>
<td>
<p>if "max", uses only labels for the maximum value in each row of
<code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smooth</code></td>
<td>
<p>a value added to the frequency of words to smooth likelihood
ratios.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boolean</code></td>
<td>
<p>if <code>TRUE</code>, only consider presence or absence of features in
each document to limit the impact of words repeated in few documents.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop_label</code></td>
<td>
<p>if <code>TRUE</code>, drops empty columns of <code>y</code> and ignore their
labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>entropy</code></td>
<td>
<p>the scheme to compute the entropy to
regularize likelihood ratios. The entropy of features are computed over
labels if <code>global</code> or over documents with the same labels if <code>local</code>. Local
entropy is averaged if <code>average</code>. See the details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residual</code></td>
<td>
<p>if <code>TRUE</code>, a residual class is added to <code>y</code>. It is named
"other" but can be changed via <code>base::options(wordmap_residual_name)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>if <code>TRUE</code>, shows progress of training.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments passed to internal functions.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Wordmap learns association between words in <code>x</code> and classes in <code>y</code>
based on likelihood ratios. The large
likelihood ratios tend to concentrate to a small number of features but the
entropy of their frequencies over labels or documents helps to disperse the
distribution.
</p>
<p>A residual class is created internally by adding a new column to <code>y</code>.
The column is given 1 if the other values in the same row are all zero
(i.e. <code>rowSums(y) == 0</code>); otherwise 0. It is useful when users cannot create
an exhaustive dictionary that covers all the categories.
</p>


<h3>Value</h3>

<p>Returns a fitted textmodel_wordmap object with the following
elements: </p>
<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a matrix that records the association between
classes and features.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>the original input of <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>feature</code></td>
<td>
<p>the feature set in <code>x</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class</code></td>
<td>
<p>the class labels in <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>concatenator</code></td>
<td>
<p>the concatenator in <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>entropy</code></td>
<td>
<p>the scheme to compute entropy weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boolean</code></td>
<td>
<p>the use of the Boolean transformation of <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the command used to execute the function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>version</code></td>
<td>
<p>the version of the wordmap package.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Watanabe, Kohei (2018). "Newsmap: semi-supervised approach to
geographical news classification". doi.org/10.1080/21670811.2017.1293487,
<em>Digital Journalism</em>.
</p>
<p>Watanabe, Kohei &amp; Zhou, Yuan (2020). "Theory-Driven Analysis of
Large Corpora: Semisupervised Topic Classification of the UN Speeches".
doi:10.1177/0894439320907027. <em>Social Science Computer Review</em>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">require(quanteda)

# split into sentences
corp &lt;- corpus_reshape(data_corpus_ungd2017)

# tokenize
toks &lt;- tokens(corp, remove_punct = TRUE) %&gt;%
   tokens_remove(stopwords("en"))

# apply seed dictionary
toks_dict &lt;- tokens_lookup(toks, data_dictionary_topic)

# form dfm
dfmt_feat &lt;- dfm(toks)
dfmt_dict &lt;- dfm(toks_dict)

# fit wordmap model
map &lt;- textmodel_wordmap(dfmt_feat, dfmt_dict)
coef(map)
predict(map)

</code></pre>


</div>