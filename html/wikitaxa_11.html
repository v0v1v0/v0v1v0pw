<div class="container">

<table style="width: 100%;"><tr>
<td>wt_wikipedia</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Wikipedia</h2>

<h3>Description</h3>

<p>Wikipedia
</p>


<h3>Usage</h3>

<pre><code class="language-R">wt_wikipedia(name, wiki = "en", utf8 = TRUE, ...)

wt_wikipedia_parse(
  page,
  types = c("langlinks", "iwlinks", "externallinks", "common_names", "classification"),
  tidy = FALSE
)

wt_wikipedia_search(
  query,
  wiki = "en",
  limit = 10,
  offset = 0,
  utf8 = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>(character) Wiki name - as a page title, must be length 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wiki</code></td>
<td>
<p>(character) wiki language. default: en. See wikipedias for
language codes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>utf8</code></td>
<td>
<p>(logical) If <code>TRUE</code>, encodes most (but not all) non-ASCII
characters as UTF-8 instead of replacing them with hexadecimal escape
sequences. Default: <code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>curl options, passed on to <code>httr::GET()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>page</code></td>
<td>
<p>(<code>httr::response()</code>) Result of <code>wt_wiki_page()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>types</code></td>
<td>
<p>(character) List of properties to parse</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>(logical). tidy output to data.frame's if possible.
Default: <code>FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>query</code></td>
<td>
<p>(character) query terms</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limit</code></td>
<td>
<p>(integer) number of results to return. Default: 10</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>(integer) record to start at. Default: 0</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>wt_wikipedia</code> returns a list, with slots:
</p>

<ul>
<li>
<p> langlinks - language page links
</p>
</li>
<li>
<p> externallinks - external links
</p>
</li>
<li>
<p> common_names - a data.frame with <code>name</code> and <code>language</code> columns
</p>
</li>
<li>
<p> classification - a data.frame with <code>rank</code> and <code>name</code> columns
</p>
</li>
<li>
<p> synonyms - a character vector with taxonomic names
</p>
</li>
</ul>
<p><code>wt_wikipedia_parse</code> returns a list with same slots determined by
the <code>types</code> parmeter
</p>
<p><code>wt_wikipedia_search</code> returns a list with slots for <code>continue</code> and
<code>query</code>, where <code>query</code> holds the results, with <code>query$search</code> slot with
the search results
</p>


<h3>References</h3>

<p><a href="https://www.mediawiki.org/wiki/API:Search">https://www.mediawiki.org/wiki/API:Search</a> for help on search
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# high level
wt_wikipedia(name = "Malus domestica")
wt_wikipedia(name = "Malus domestica", wiki = "fr")
wt_wikipedia(name = "Malus domestica", wiki = "da")

# low level
pg &lt;- wt_wiki_page("https://en.wikipedia.org/wiki/Malus_domestica")
wt_wikipedia_parse(pg)
wt_wikipedia_parse(pg, tidy = TRUE)

# search wikipedia
# FIXME: utf=FALSE for now until curl::curl_escape fix 
# https://github.com/jeroen/curl/issues/228
wt_wikipedia_search(query = "Pinus", utf8=FALSE)
wt_wikipedia_search(query = "Pinus", wiki = "fr", utf8=FALSE)
wt_wikipedia_search(query = "Pinus", wiki = "br", utf8=FALSE)

## curl options
# wt_wikipedia_search(query = "Pinus", verbose = TRUE, utf8=FALSE)

## use search results to dig into pages
res &lt;- wt_wikipedia_search(query = "Pinus", utf8=FALSE)
lapply(res$query$search$title[1:3], wt_wikipedia)

## End(Not run)
</code></pre>


</div>